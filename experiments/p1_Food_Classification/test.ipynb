{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-01T14:14:11.908546Z",
     "iopub.status.busy": "2022-12-01T14:14:11.908144Z",
     "iopub.status.idle": "2022-12-01T14:14:12.243030Z",
     "shell.execute_reply": "2022-12-01T14:14:12.242035Z",
     "shell.execute_reply.started": "2022-12-01T14:14:11.908502Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from models import ResNet, BaseNet\n",
    "from utils import same_seeds, all_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:14:14.526793Z",
     "iopub.status.busy": "2022-12-01T14:14:14.526302Z",
     "iopub.status.idle": "2022-12-01T14:14:14.534453Z",
     "shell.execute_reply": "2022-12-01T14:14:14.533660Z",
     "shell.execute_reply.started": "2022-12-01T14:14:14.526745Z"
    }
   },
   "outputs": [],
   "source": [
    "# 一般情况下，我们不会在验证集和测试集上做数据扩增\n",
    "# 我们只需要将图片裁剪成同样的大小并装换成Tensor就行\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 当然，我们也可以再测试集中对数据进行扩增（对同样本的不同装换）\n",
    "#  - 用训练数据的装化方法（train_tfm）去对测试集数据进行转化，产出扩增样本\n",
    "#  - 对同个照片的不同样本分别进行预测\n",
    "#  - 最后可以用soft vote / hard vote 等集成方法输出最后的预测\n",
    "train_tfm = transforms.Compose([\n",
    "    # 图片裁剪 (height = width = 128)\n",
    "    transforms.Resize((128, 128)),\n",
    "    # TODO:在这部分还可以增加一些图片处理的操作\n",
    "    transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n",
    "    # ToTensor() 放在所有处理的最后\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:14:14.536424Z",
     "iopub.status.busy": "2022-12-01T14:14:14.535910Z",
     "iopub.status.idle": "2022-12-01T14:14:14.547727Z",
     "shell.execute_reply": "2022-12-01T14:14:14.546369Z",
     "shell.execute_reply.started": "2022-12-01T14:14:14.536383Z"
    }
   },
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "\n",
    "    def __init__(self,path,tfm=test_tfm,files = None):\n",
    "        super(FoodDataset).__init__()\n",
    "        self.path = path\n",
    "        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n",
    "        if files != None:\n",
    "            self.files = files\n",
    "        print(f\"One {path} sample\",self.files[0])\n",
    "        self.transform = tfm\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "  \n",
    "    def __getitem__(self,idx):\n",
    "        fname = self.files[idx]\n",
    "        im = Image.open(fname)\n",
    "        im = self.transform(im)\n",
    "        try:\n",
    "            label = int(fname.split(\"\\\\\")[-1].split(\"_\")[0])\n",
    "        except:\n",
    "            label = -1 # 测试集没有label\n",
    "        return im,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:14:16.228399Z",
     "iopub.status.busy": "2022-12-01T14:14:16.227938Z",
     "iopub.status.idle": "2022-12-01T14:14:16.240770Z",
     "shell.execute_reply": "2022-12-01T14:14:16.239849Z",
     "shell.execute_reply.started": "2022-12-01T14:14:16.228358Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "config = {\n",
    "    'seed': 6666,\n",
    "    'dataset_dir': \"./data/food11\",\n",
    "    'n_epochs': 50,      \n",
    "    'batch_size': 128, \n",
    "    'learning_rate': 0.001,           \n",
    "    'weight_decay':1e-5,\n",
    "    'early_stop': 300,\n",
    "    'clip_flag': True, \n",
    "    'save_path': './models/model.ckpt',\n",
    "    'resnet_save_path': './models/resnet_model.ckpt'\n",
    "}\n",
    "print(device)\n",
    "all_seed(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:14:39.395140Z",
     "iopub.status.busy": "2022-12-01T14:14:39.394370Z",
     "iopub.status.idle": "2022-12-01T14:14:39.755938Z",
     "shell.execute_reply": "2022-12-01T14:14:39.754870Z",
     "shell.execute_reply.started": "2022-12-01T14:14:39.395100Z"
    }
   },
   "outputs": [],
   "source": [
    "_dataset_dir = config['dataset_dir']\n",
    "\n",
    "train_set = FoodDataset(os.path.join(_dataset_dir,\"training\"), tfm=train_tfm)\n",
    "train_loader = DataLoader(train_set, batch_size=config['batch_size'], shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "valid_set = FoodDataset(os.path.join(_dataset_dir,\"validation\"), tfm=test_tfm)\n",
    "valid_loader = DataLoader(valid_set, batch_size=config['batch_size'], shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "# 测试级保证输出顺序一致\n",
    "test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=test_tfm)\n",
    "test_loader = DataLoader(test_set, batch_size=config['batch_size'], shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:14:58.424611Z",
     "iopub.status.busy": "2022-12-01T14:14:58.423498Z",
     "iopub.status.idle": "2022-12-01T14:14:58.455367Z",
     "shell.execute_reply": "2022-12-01T14:14:58.454288Z",
     "shell.execute_reply.started": "2022-12-01T14:14:58.424573Z"
    }
   },
   "outputs": [],
   "source": [
    "test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=train_tfm)\n",
    "test_loader_extra1 = DataLoader(test_set, batch_size=config['batch_size'], shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=train_tfm)\n",
    "test_loader_extra2 = DataLoader(test_set, batch_size=config['batch_size'], shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=train_tfm)\n",
    "test_loader_extra3 = DataLoader(test_set, batch_size=config['batch_size'], shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:40:03.813830Z",
     "iopub.status.busy": "2022-12-01T14:40:03.813183Z",
     "iopub.status.idle": "2022-12-01T14:40:03.947539Z",
     "shell.execute_reply": "2022-12-01T14:40:03.946198Z",
     "shell.execute_reply.started": "2022-12-01T14:40:03.813792Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model_best = BaseNet().to(device)\n",
    "model_best.load_state_dict(torch.load('checkpoints/20250828_203602/best_checkpoint.pt'))\n",
    "model_best.eval()\n",
    "prediction = []\n",
    "with torch.no_grad():\n",
    "    for data,_ in test_loader:\n",
    "        test_pred = model_best(data.to(device))\n",
    "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
    "        prediction += test_label.squeeze().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:40:29.042468Z",
     "iopub.status.busy": "2022-12-01T14:40:29.042085Z",
     "iopub.status.idle": "2022-12-01T14:42:47.685883Z",
     "shell.execute_reply": "2022-12-01T14:42:47.684977Z",
     "shell.execute_reply.started": "2022-12-01T14:40:29.042434Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loaders = [test_loader_extra1, test_loader_extra2, test_loader_extra3, test_loader]\n",
    "loader_nums = len(test_loaders)\n",
    "# 存储每个dataloader预测结果，一个dataloader一个数组\n",
    "loader_pred_list = []\n",
    "for idx, d_loader in enumerate(test_loaders):\n",
    "    # 存储一个dataloader的预测结果,  一个batch一个是数组\n",
    "    pred_arr_list = [] \n",
    "    with torch.no_grad():\n",
    "        tq_bar = tqdm(d_loader)\n",
    "        tq_bar.set_description(f\"[ DataLoader {idx+1}/{loader_nums} ]\")\n",
    "        for data,_ in tq_bar:\n",
    "            test_pred = model_best(data.to(device))\n",
    "            logit_pred = test_pred.cpu().data.numpy()\n",
    "            pred_arr_list.append(logit_pred)\n",
    "        # 将每个batch的预测结果合并成一个数组\n",
    "        loader_pred_list.append( np.concatenate(pred_arr_list, axis=0) )\n",
    "\n",
    "\n",
    "# 将预测结果合并\n",
    "pred_arr = np.zeros(loader_pred_list[0].shape)\n",
    "for pred_arr_t in loader_pred_list:\n",
    "    pred_arr += pred_arr_t\n",
    "\n",
    "\n",
    "soft_vote_prediction = np.argmax(0.5 * pred_arr / len(loader_pred_list) + 0.5 * loader_pred_list[-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:42:47.688278Z",
     "iopub.status.busy": "2022-12-01T14:42:47.687892Z",
     "iopub.status.idle": "2022-12-01T14:42:47.712049Z",
     "shell.execute_reply": "2022-12-01T14:42:47.710767Z",
     "shell.execute_reply.started": "2022-12-01T14:42:47.688241Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "# 保证ID为四位数（前面填充0）\n",
    "df[\"Id\"] = [str(i).zfill(4) for i in range(1, len(test_set)+1)]\n",
    "df[\"Category\"] = soft_vote_prediction\n",
    "df.to_csv(\"submission.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XMem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
