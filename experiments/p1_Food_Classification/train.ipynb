{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4388ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some needed libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68cacc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_logger(log_name, log_path, show_time=False):\n",
    "    # create a logger\n",
    "    logger = logging.getLogger(log_name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.propagate = True\n",
    "    # create a handler\n",
    "    handler = logging.FileHandler(log_path)\n",
    "    # create a formatter\n",
    "    if show_time:\n",
    "        formatter = logging.Formatter(fmt='%(asctime)s - %(message)s')\n",
    "    else:\n",
    "        formatter = logging.Formatter(fmt='%(message)s')\n",
    "    # assemble them\n",
    "    logger.addHandler(handler)\n",
    "    handler.setFormatter(formatter)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6962357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seeds\n",
    "def same_seeds(seed): # 固定随机种子（CPU）\n",
    "    torch.manual_seed(seed) # 固定随机种子（GPU)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed) # 为当前GPU设置\n",
    "        torch.cuda.manual_seed_all(seed)  # 为所有GPU设置\n",
    "    np.random.seed(seed)  # 保证后续使用random函数时，产生固定的随机数\n",
    "    torch.backends.cudnn.benchmark = False # GPU、网络结构固定，可设置为True\n",
    "    torch.backends.cudnn.deterministic = True # 固定网络结构\n",
    "\n",
    "\n",
    "# define the global seed\n",
    "def all_seed(seed = 6666):\n",
    "    \"\"\"\n",
    "    设置随机种子\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    # CPU\n",
    "    torch.manual_seed(seed) \n",
    "    # GPU\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.cuda.manual_seed(seed) \n",
    "    # python 全局\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
    "    # cudnn\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    print(f'Set env random_seed = {seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8623bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre-procession\n",
    "def read_images(imgs_dir_root, data_tag='training', resize_shape=128):\n",
    "    '''\n",
    "    ---\n",
    "    PARAS\n",
    "    ---\n",
    "    imgs_path: str, the file storaged the images\n",
    "    data_tag: str, 'training', 'test', 'validation'\n",
    "\n",
    "    ---\n",
    "    RETURN\n",
    "    --- \n",
    "    return a torch array that storages the images data\n",
    "\n",
    "    '''\n",
    "    imgs_dir_root = os.path.join(imgs_dir_root, data_tag)\n",
    "    test_tfm = transforms.Compose([\n",
    "        transforms.Resize((resize_shape, resize_shape)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_tfm = transforms.Compose([\n",
    "        transforms.Resize((resize_shape, resize_shape)),\n",
    "        # AutoAugment: Learning Augmentation Strategies from Data \"<https://arxiv.org/pdf/1805.09501.pdf>\"\n",
    "        transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    images_list, labels_list, nimages_list = None, None, None\n",
    "    if data_tag == 'training' or data_tag == 'validation':\n",
    "        nimages_list = os.listdir(imgs_dir_root)\n",
    "        # need a shuffle to the nimages_list\n",
    "        labels_list = [int(nimage.split('_')[0]) for nimage in nimages_list]\n",
    "        images_list = [train_tfm(Image.open(os.path.join(imgs_dir_root, nfile))) \n",
    "                      for nfile in nimages_list]\n",
    "\n",
    "    elif data_tag == 'test':\n",
    "        nimages_list = os.listdir(imgs_dir_root)\n",
    "        images_list = [test_tfm(Image.open(os.path.join(imgs_dir_root, nfile))) \n",
    "                      for nfile in nimages_list]\n",
    "        labels_list = None\n",
    "\n",
    "    return images_list, labels_list, nimages_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae097a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Food_Dataset(utils.data.Dataset):\n",
    "    def __init__(self, images_list, labels_list=None):\n",
    "        super(Food_Dataset, self).__init__()\n",
    "        self.images = images_list\n",
    "        self.labels = labels_list\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.labels is not None:\n",
    "            return (len(self.images) == len(self.labels)) * len(self.images)\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.labels is not None:\n",
    "            return self.images[index], self.labels[index]\n",
    "        return self.images[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c164e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNet, self).__init__()\n",
    "        # input [3, 128, 128]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n",
    "            \n",
    "            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 11)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53bc29a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, val_dataloader, config, model, device, logger_train, logger_val, pre_train):\n",
    "    add_epoch, add_step = pre_train\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                 lr = config['lr'], \n",
    "                                 weight_decay=config['weight_decay'])\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=config['lr'])\n",
    "    best_acc = 0.0\n",
    "    early_stop_count = 0\n",
    "    step = 1\n",
    "\n",
    "    for epoch in range(config['n_epoch']):\n",
    "\n",
    "        # strat training\n",
    "        model.train()\n",
    "        train_loss_list, train_acc_list = [], []\n",
    "        for imgs, labels in tqdm(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            # 稳定训练的技巧\n",
    "            if config['clip_flag']:\n",
    "                grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "            \n",
    "            optimizer.step()\n",
    "            _, train_pred = torch.max(outputs, dim=1) # find the biggest value along the line\n",
    "            train_acc_list.append((train_pred.detach() == labels.detach()).sum().item())\n",
    "            train_loss_list.append(loss.item())\n",
    "            if step % 10 == 0:\n",
    "                logger_train.info(f'step {add_step+step:03d} train loss {loss.item():3.6f} train acc {((train_pred.detach() == labels.detach()).sum().item()) / len(imgs):3.6f}')\n",
    "            step += 1\n",
    "        \n",
    "        # record the training info\n",
    "        train_loss = sum(train_loss_list) / len(train_loss_list)\n",
    "        train_acc = sum(train_acc_list) / (config['batch_size'] * len(train_acc_list))\n",
    "        logger_train.info(f\"EPOCH [{add_epoch+epoch+1:03d}|{add_epoch+config['n_epoch']:03d}] TRAIN LOSS {train_loss:3.6f} TRAIN ACC {train_acc:3.6f}\")\n",
    "        print(f\"EPOCH [{add_epoch+epoch+1:03d}|{add_epoch+config['n_epoch']:03d}] TRAIN LOSS {train_loss:3.6f} TRAIN ACC {train_acc:3.6f}\")\n",
    "\n",
    "\n",
    "        # start valiation\n",
    "        model.eval()\n",
    "        val_acc_list, val_loss_list = [], []\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(val_dataloader):\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, val_pred = torch.max(outputs, dim = 1)\n",
    "                val_acc_list.append((val_pred.detach() == labels.detach()).sum().item())\n",
    "                val_loss_list.append(loss.item())\n",
    "        \n",
    "        # record the val info\n",
    "        val_loss = sum(val_loss_list) / len(val_loss_list)\n",
    "        val_acc = sum(val_acc_list) / (config['batch_size'] * len(val_acc_list))\n",
    "        logger_val.info(f\"EPOCH [{add_epoch+epoch+1:03d}|{add_epoch+config['n_epoch']:03d}] VAL LOSS {val_loss:3.6f} VAL ACC {val_acc:3.6f}\")\n",
    "        print(f\"EPOCH [{add_epoch+epoch+1:03d}|{add_epoch+config['n_epoch']:03d}] VAL LOSS {val_loss:3.6f} VAL ACC {val_acc:3.6f}\")\n",
    "\n",
    "        # save the best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), f\"{config['checkpoints_dir']}/best_checkpoint.pt\")\n",
    "            print(f'saving the best model with val acc: {best_acc:3.6f}')\n",
    "            early_stop_count = 0\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "\n",
    "        # early stop\n",
    "        if early_stop_count >= config['early_stop']:\n",
    "            print('\\nModel is not improving, so halt the training session.')\n",
    "            \n",
    "            \n",
    "    # save the latest model for belowing training     \n",
    "    torch.save(model.state_dict(), f\"{config['checkpoints_dir']}/latest_checkpoint.pt\")\n",
    "    print(f\"saving the latest model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a8f853c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set env random_seed = 6666\n",
      "DEVICE:cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:17<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [001|100] TRAIN LOSS 2.273899 TRAIN ACC 0.194095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [001|100] VAL LOSS 2.222982 VAL ACC 0.192909\n",
      "saving the best model with val acc: 0.192909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:17<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [002|100] TRAIN LOSS 2.100618 TRAIN ACC 0.265219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 10.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [002|100] VAL LOSS 2.090106 VAL ACC 0.268630\n",
      "saving the best model with val acc: 0.268630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:17<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [003|100] TRAIN LOSS 1.979142 TRAIN ACC 0.319298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00,  9.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [003|100] VAL LOSS 2.014100 VAL ACC 0.320913\n",
      "saving the best model with val acc: 0.320913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:18<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [004|100] TRAIN LOSS 1.865118 TRAIN ACC 0.350548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [004|100] VAL LOSS 2.003217 VAL ACC 0.294171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:19<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [005|100] TRAIN LOSS 1.760790 TRAIN ACC 0.386567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [005|100] VAL LOSS 1.857027 VAL ACC 0.354567\n",
      "saving the best model with val acc: 0.354567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:19<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [006|100] TRAIN LOSS 1.658817 TRAIN ACC 0.424513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [006|100] VAL LOSS 1.734964 VAL ACC 0.408353\n",
      "saving the best model with val acc: 0.408353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:17<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [007|100] TRAIN LOSS 1.566923 TRAIN ACC 0.452821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [007|100] VAL LOSS 1.790058 VAL ACC 0.388221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:17<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [008|100] TRAIN LOSS 1.490121 TRAIN ACC 0.482346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [008|100] VAL LOSS 1.801004 VAL ACC 0.378606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:17<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [009|100] TRAIN LOSS 1.412630 TRAIN ACC 0.508929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 10.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [009|100] VAL LOSS 1.764232 VAL ACC 0.413462\n",
      "saving the best model with val acc: 0.413462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:18<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [010|100] TRAIN LOSS 1.339168 TRAIN ACC 0.534903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [010|100] VAL LOSS 1.729841 VAL ACC 0.420373\n",
      "saving the best model with val acc: 0.420373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:18<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [011|100] TRAIN LOSS 1.260377 TRAIN ACC 0.561688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [011|100] VAL LOSS 2.411820 VAL ACC 0.318810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:17<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [012|100] TRAIN LOSS 1.178190 TRAIN ACC 0.593344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 10.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [012|100] VAL LOSS 1.600648 VAL ACC 0.460938\n",
      "saving the best model with val acc: 0.460938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:17<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [013|100] TRAIN LOSS 1.084322 TRAIN ACC 0.621652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [013|100] VAL LOSS 1.635768 VAL ACC 0.478365\n",
      "saving the best model with val acc: 0.478365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:17<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [014|100] TRAIN LOSS 1.004398 TRAIN ACC 0.655438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [014|100] VAL LOSS 1.841349 VAL ACC 0.442007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:18<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [015|100] TRAIN LOSS 0.936128 TRAIN ACC 0.675629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00, 10.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [015|100] VAL LOSS 2.238690 VAL ACC 0.390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:19<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [016|100] TRAIN LOSS 0.836663 TRAIN ACC 0.713981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00,  9.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [016|100] VAL LOSS 1.776462 VAL ACC 0.472957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:19<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [017|100] TRAIN LOSS 0.739967 TRAIN ACC 0.742188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:02<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [017|100] VAL LOSS 2.147530 VAL ACC 0.443510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 5/77 [00:06<01:28,  1.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m note_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMODEL INFO:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(my_model)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     50\u001b[0m note_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCONFIG INFO:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpprint\u001b[38;5;241m.\u001b[39mpformat(config,\u001b[38;5;250m \u001b[39mindent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 51\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmy_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_logger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_logger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_dataloader, val_dataloader, config, model, device, logger_train, logger_val, pre_train)\u001b[0m\n\u001b[0;32m     21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(imgs)\n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 23\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 稳定训练的技巧\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip_flag\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\XMem\\lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\XMem\\lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\XMem\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    \n",
    "config = {\n",
    "    # =============================================\n",
    "    'data_dir':'./data/food11',\n",
    "    'checkpoints_dir':f'./checkpoints/{timestamp}',\n",
    "    'loggers_dir':f'./loggers/{timestamp}',\n",
    "    # =============================================\n",
    "    'seed': 6666,\n",
    "    'n_epoch': 100,\n",
    "    'batch_size': 128,\n",
    "    'lr':0.0005,\n",
    "    'weight_decay':1e-3,\n",
    "    'early_stop': 25,\n",
    "    'num_workers': 0,\n",
    "    'clip_flag': True,\n",
    "    # =============================================\n",
    "}\n",
    "all_seed(config['seed'])\n",
    "if not os.path.exists(config['checkpoints_dir']):\n",
    "    os.makedirs(config['checkpoints_dir'], mode=0o755)\n",
    "if not os.path.exists(config['loggers_dir']):\n",
    "    os.makedirs(config['loggers_dir'], mode=0o755)\n",
    "train_images_list, train_labels_list, _ = read_images(config['data_dir'], 'training', resize_shape=128)\n",
    "val_images_list, val_labels_list, _ = read_images(config['data_dir'], 'validation', resize_shape=128)\n",
    "train_set = Food_Dataset(train_images_list, train_labels_list)\n",
    "val_set = Food_Dataset(val_images_list, val_labels_list)\n",
    "del train_images_list, train_labels_list, val_images_list, val_labels_list\n",
    "train_dataloader = utils.data.DataLoader(train_set, batch_size=config['batch_size'], \n",
    "                                        shuffle=True, num_workers=config['num_workers'], \n",
    "                                        pin_memory=True, drop_last=True)\n",
    "val_dataloader = utils.data.DataLoader(val_set, batch_size=config['batch_size'], \n",
    "                                        shuffle=True, num_workers=config['num_workers'], \n",
    "                                        pin_memory=True, drop_last=True)\n",
    "print(f\"DEVICE:{device}\")\n",
    "my_model = BaseNet().to(device)\n",
    "# my_model = ResNet().to(device)\n",
    "# from torchvision.models import resnet50\n",
    "# my_model = resnet50(pretrained=True).to(device)\n",
    "# time_tag = 20250827_174759\n",
    "# my_model.load_state_dict(torch.load(f\"checkpoints/20250827_174759/latest_checkpoint.pt\", map_location=device))\n",
    "    \n",
    "train_logger = create_logger('train_logger', f\"{config['loggers_dir']}/train.log\", show_time=False)\n",
    "val_logger = create_logger('val_logger', f\"{config['loggers_dir']}/val.log\", show_time=False)\n",
    "note_logger = create_logger('note_logger', f\"{config['loggers_dir']}/note.log\", show_time=True)\n",
    "note_logger.info(f'DEVICE:\\n{device}')\n",
    "note_logger.info(f'MODEL INFO:\\n{str(my_model)}')\n",
    "note_logger.info(f'CONFIG INFO:\\n{pprint.pformat(config, indent=4)}')\n",
    "train(train_dataloader, val_dataloader, config, my_model, device, train_logger, val_logger, pre_train=[0, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XMem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
